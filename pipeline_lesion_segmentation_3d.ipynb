{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3DRDNN\n",
    "\n",
    "Main pipeline for research in my Master.\n",
    "\n",
    "## goals in this notebook\n",
    "\n",
    "Prepare the pipeline for any 3d DNN to train on CT data.\n",
    "1) data loader\n",
    "2) DNN\n",
    "3) Training\n",
    "4) Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.8.0\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Testing reading GPU\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print(\"TensorFlow Version: {}\".format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn(\"No GPU found. Please ensure you have installed TensorFlow correctly\")\n",
    "else:\n",
    "    print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images0.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images1.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images2.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images3.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images4.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images5.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images6.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images7.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images8.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\train\\\\images9.tfrecords']\n",
      "['C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\valid\\\\images10.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\valid\\\\images11.tfrecords', 'C:\\\\Users\\\\kaczm\\\\programming\\\\3DRDNN\\\\data\\\\LITS_TFRecords\\\\valid\\\\images12.tfrecords']\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "(4, 64, 64, 64, 1)\n",
      "(4, 64, 64, 64, 2)\n",
      "0.0\n",
      "1.0\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, None, None, None), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, None, None, None), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, None, None, None), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, None, None, None), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# datasets for tf\n",
    "from data_preprocessing_3d import get_dataset_large\n",
    "\n",
    "batch_size = 4\n",
    "dataset = get_dataset_large(\n",
    "    r\"C:\\Users\\kaczm\\programming\\3DRDNN\\data\\LITS_TFRecords\\train\"\n",
    ")\n",
    "dataset = dataset.shuffle(8).batch(batch_size)\n",
    "valid_dataset = get_dataset_large(\n",
    "    r\"C:\\Users\\kaczm\\programming\\3DRDNN\\data\\LITS_TFRecords\\valid\"\n",
    ")\n",
    "valid_dataset = valid_dataset.batch(\n",
    "    batch_size\n",
    ")  # .shuffle(1000,  reshuffle_each_iteration=True)\n",
    "\n",
    "for sample in dataset.take(1):\n",
    "    print(sample[0].shape)\n",
    "    print(sample[1].shape)\n",
    "\n",
    "for sample in valid_dataset.take(10):\n",
    "    print(sample[0].shape)\n",
    "    print(sample[1].shape)\n",
    "    print(np.min(sample[0]))\n",
    "    print(np.max(sample[0]))\n",
    "\n",
    "print(dataset)\n",
    "print(valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### learning rate schedule\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        lr = 0.001\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network set-up\n",
    "from utils import models\n",
    "\n",
    "model = models.model_call(model_name=\"3DUNET\", pxz=32, px=64, features=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape                    Param #     Connected to          \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 64, 64, 1)]         0           []                    \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 32, 64, 64, 32)          896         ['input_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 64, 64, 32)         128         ['conv3d[0][0]']      \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 32, 64, 64, 64)          18496       ['batch_normalization[\n",
      "                                                                            0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 16, 32, 32, 64)          0           ['conv3d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 32, 32, 64)         256         ['max_pooling3d[0][0]'\n",
      " rmalization)                                                               ]                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 16, 32, 32, 64)          0           ['batch_normalization_\n",
      "                                                                            1[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 16, 32, 32, 64)          110656      ['dropout[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 32, 32, 64)         256         ['conv3d_2[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 16, 32, 32, 128)         221312      ['batch_normalization_\n",
      "                                                                            2[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 8, 16, 16, 128)         0           ['conv3d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 16, 16, 128)         512         ['max_pooling3d_1[0][0\n",
      " rmalization)                                                               ]']                   \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 8, 16, 16, 128)          0           ['batch_normalization_\n",
      "                                                                            3[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 8, 16, 16, 128)          442496      ['dropout_1[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 16, 16, 128)         512         ['conv3d_4[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 8, 16, 16, 256)          884992      ['batch_normalization_\n",
      "                                                                            4[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 4, 8, 8, 256)           0           ['conv3d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 8, 8, 256)           1024        ['max_pooling3d_2[0][0\n",
      " rmalization)                                                               ]']                   \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 8, 8, 256)            0           ['batch_normalization_\n",
      "                                                                            5[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 4, 8, 8, 256)            1769728     ['dropout_2[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 8, 8, 256)           1024        ['conv3d_6[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 4, 8, 8, 512)            3539456     ['batch_normalization_\n",
      "                                                                            6[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 8, 16, 16, 512)         7078400     ['conv3d_7[0][0]']    \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 16, 16, 768)          0           ['conv3d_transpose[0][\n",
      "                                                                            0]',                  \n",
      "                                                                             'conv3d_5[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 8, 16, 16, 768)          0           ['concatenate[0][0]'] \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 8, 16, 16, 256)          5308672     ['dropout_3[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 8, 16, 16, 256)         1024        ['conv3d_8[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 8, 16, 16, 256)          1769728     ['batch_normalization_\n",
      "                                                                            7[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 16, 32, 32, 256)        1769728     ['conv3d_9[0][0]']    \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 32, 32, 384)         0           ['conv3d_transpose_1[0\n",
      "                                                                            ][0]',                \n",
      "                                                                             'conv3d_3[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 16, 32, 32, 384)         0           ['concatenate_1[0][0]'\n",
      "                                                                            ]                     \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 16, 32, 32, 128)         1327232     ['dropout_4[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 32, 32, 128)        512         ['conv3d_10[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 16, 32, 32, 128)         442496      ['batch_normalization_\n",
      "                                                                            9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 32, 32, 128)        512         ['conv3d_11[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 32, 64, 64, 128)        442496      ['batch_normalization_\n",
      " spose)                                                                     10[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 64, 64, 192)         0           ['conv3d_transpose_2[0\n",
      "                                                                            ][0]',                \n",
      "                                                                             'conv3d_1[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32, 64, 64, 192)         0           ['concatenate_2[0][0]'\n",
      "                                                                            ]                     \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 32, 64, 64, 64)          331840      ['dropout_5[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 64, 64, 64)         256         ['conv3d_12[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 32, 64, 64, 64)          110656      ['batch_normalization_\n",
      "                                                                            11[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 32, 64, 64, 2)           130         ['conv3d_13[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,575,426\n",
      "Trainable params: 25,572,418\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Metrics and training\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.00001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\",\n",
    ")\n",
    "precision_all = tf.keras.metrics.Precision(thresholds=0.5)\n",
    "precision = tf.keras.metrics.Precision(thresholds=0.5, class_id=1)\n",
    "recall = tf.keras.metrics.Recall(thresholds=0.5, class_id=1)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=adam,\n",
    "    metrics=[precision_all, precision, recall],\n",
    ")\n",
    "model.summary(positions=[0.33, 0.66, 0.78, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[202], line 28\u001b[0m\n\u001b[0;32m     14\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[0;32m     15\u001b[0m     \u001b[39m# EarlyStopping(patience=10, verbose=1),\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[39m#ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.0000001, verbose=1),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     TerminateOnNaN(),\n\u001b[0;32m     25\u001b[0m ]\n\u001b[0;32m     26\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[1;32m---> 28\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     29\u001b[0m     dataset,\n\u001b[0;32m     30\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     31\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_dataset,\n\u001b[0;32m     32\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m     33\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m hist_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(history\u001b[39m.\u001b[39mhistory) \n\u001b[0;32m     39\u001b[0m \u001b[39m# save to json:  \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2955\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2952\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m-> 2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mgraph_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3288\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[0;32m   3291\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd_call_context(cache_key\u001b[39m.\u001b[39mcall_context)\n\u001b[1;32m-> 3292\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   3293\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   3294\u001b[0m                          graph_function)\n\u001b[0;32m   3296\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3125\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   3126\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3127\u001b[0m ]\n\u001b[0;32m   3128\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   3129\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3130\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   3131\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   3132\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   3133\u001b[0m         args,\n\u001b[0;32m   3134\u001b[0m         kwargs,\n\u001b[0;32m   3135\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   3136\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   3137\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   3138\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   3139\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[0;32m   3140\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   3141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   3142\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   3143\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3144\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3145\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3147\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   3148\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1159\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1161\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1163\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1166\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1136\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1136\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1137\u001b[0m       original_func,\n\u001b[0;32m   1138\u001b[0m       args,\n\u001b[0;32m   1139\u001b[0m       kwargs,\n\u001b[0;32m   1140\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1141\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1142\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1143\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1144\u001b[0m       ))\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileldo_vjkr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\training.py:1010\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1007\u001b[0m   run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1008\u001b[0m       run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, experimental_relax_shapes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1009\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1010\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1011\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1012\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1013\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\training.py:1000\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    999\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1000\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1001\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\training.py:864\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mminimize(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables, tape\u001b[39m=\u001b[39mtape)\n\u001b[1;32m--> 864\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\training.py:957\u001b[0m, in \u001b[0;36mModel.compute_metrics\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[39m\"\"\"Update metric states and collect all metrics to be returned.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \n\u001b[0;32m    924\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom metric\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[39m  `{'loss': 0.2, 'accuracy': 0.7}`.\u001b[39;00m\n\u001b[0;32m    955\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[1;32m--> 957\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_metrics\u001b[39m.\u001b[39;49mupdate_state(y, y_pred, sample_weight)\n\u001b[0;32m    958\u001b[0m \u001b[39m# Collect metrics to return\u001b[39;00m\n\u001b[0;32m    959\u001b[0m return_metrics \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\engine\\compile_utils.py:459\u001b[0m, in \u001b[0;36mMetricsContainer.update_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[39mif\u001b[39;00m metric_obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 459\u001b[0m   metric_obj\u001b[39m.\u001b[39;49mupdate_state(y_t, y_p, sample_weight\u001b[39m=\u001b[39;49mmask)\n\u001b[0;32m    461\u001b[0m \u001b[39mfor\u001b[39;00m weighted_metric_obj \u001b[39min\u001b[39;00m weighted_metric_objs:\n\u001b[0;32m    462\u001b[0m   \u001b[39mif\u001b[39;00m weighted_metric_obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\utils\\metrics_utils.py:70\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTrying to run metric.update_state in replica context when \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMake sure the keras Metric is created in TPUstrategy scope. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 70\u001b[0m   update_op \u001b[39m=\u001b[39m update_state_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# update_op will be None in eager execution.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m   metric_obj\u001b[39m.\u001b[39madd_update(update_op)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\metrics.py:178\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m control_status \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    177\u001b[0m ag_update_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(obj_update_state, control_status)\n\u001b[1;32m--> 178\u001b[0m \u001b[39mreturn\u001b[39;00m ag_update_state(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\metrics.py:1533\u001b[0m, in \u001b[0;36mRecall.update_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_state\u001b[39m(\u001b[39mself\u001b[39m, y_true, y_pred, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1520\u001b[0m   \u001b[39m\"\"\"Accumulates true positive and false negative statistics.\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \n\u001b[0;32m   1522\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[39m    Update op.\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1533\u001b[0m   \u001b[39mreturn\u001b[39;00m metrics_utils\u001b[39m.\u001b[39;49mupdate_confusion_matrix_variables(\n\u001b[0;32m   1534\u001b[0m       {\n\u001b[0;32m   1535\u001b[0m           metrics_utils\u001b[39m.\u001b[39;49mConfusionMatrix\u001b[39m.\u001b[39;49mTRUE_POSITIVES: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrue_positives,\n\u001b[0;32m   1536\u001b[0m           metrics_utils\u001b[39m.\u001b[39;49mConfusionMatrix\u001b[39m.\u001b[39;49mFALSE_NEGATIVES: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfalse_negatives\n\u001b[0;32m   1537\u001b[0m       },\n\u001b[0;32m   1538\u001b[0m       y_true,\n\u001b[0;32m   1539\u001b[0m       y_pred,\n\u001b[0;32m   1540\u001b[0m       thresholds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthresholds,\n\u001b[0;32m   1541\u001b[0m       thresholds_distributed_evenly\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_thresholds_distributed_evenly,\n\u001b[0;32m   1542\u001b[0m       top_k\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_k,\n\u001b[0;32m   1543\u001b[0m       class_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_id,\n\u001b[0;32m   1544\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\keras\\utils\\metrics_utils.py:606\u001b[0m, in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights, thresholds_distributed_evenly)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mif\u001b[39;00m invalid_keys:\n\u001b[0;32m    597\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    598\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInvalid keys: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00minvalid_keys\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    599\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValid variable key options are: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(ConfusionMatrix)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies([\n\u001b[0;32m    602\u001b[0m     tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39massert_greater_equal(\n\u001b[0;32m    603\u001b[0m         y_pred,\n\u001b[0;32m    604\u001b[0m         tf\u001b[39m.\u001b[39mcast(\u001b[39m0.0\u001b[39m, dtype\u001b[39m=\u001b[39my_pred\u001b[39m.\u001b[39mdtype),\n\u001b[0;32m    605\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredictions must be >= 0\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m--> 606\u001b[0m     tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49massert_less_equal(\n\u001b[0;32m    607\u001b[0m         y_pred,\n\u001b[0;32m    608\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(\u001b[39m1.0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49my_pred\u001b[39m.\u001b[39;49mdtype),\n\u001b[0;32m    609\u001b[0m         message\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpredictions must be <= 1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    610\u001b[0m ]):\n\u001b[0;32m    611\u001b[0m   \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[0;32m    613\u001b[0m         y_pred, y_true)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py:998\u001b[0m, in \u001b[0;36massert_less_equal\u001b[1;34m(x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdebugging.assert_less_equal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39massert_less_equal\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    994\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    995\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_endpoints(\u001b[39m'\u001b[39m\u001b[39massert_less_equal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    996\u001b[0m \u001b[39m@_binary_assert_doc\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m<=\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m[1, 3]\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    997\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39massert_less_equal\u001b[39m(x, y, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, summarize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, message\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 998\u001b[0m   \u001b[39mreturn\u001b[39;00m _binary_assert(\u001b[39m'\u001b[39;49m\u001b[39m<=\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39massert_less_equal\u001b[39;49m\u001b[39m'\u001b[39;49m, math_ops\u001b[39m.\u001b[39;49mless_equal,\n\u001b[0;32m    999\u001b[0m                         np\u001b[39m.\u001b[39;49mless_equal, x, y, data, summarize, message, name)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py:425\u001b[0m, in \u001b[0;36m_binary_assert\u001b[1;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    423\u001b[0m   condition_static \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mall(static_func(x_static, y_static))\n\u001b[0;32m    424\u001b[0m   _assert_static(condition_static, data)\n\u001b[1;32m--> 425\u001b[0m \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39;49mAssert(condition, data, summarize\u001b[39m=\u001b[39;49msummarize)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:243\u001b[0m, in \u001b[0;36mshould_use_result.<locals>.decorated.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 243\u001b[0m   \u001b[39mreturn\u001b[39;00m _add_should_use_warning(fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs),\n\u001b[0;32m    244\u001b[0m                                  warn_in_eager\u001b[39m=\u001b[39mwarn_in_eager,\n\u001b[0;32m    245\u001b[0m                                  error_in_function\u001b[39m=\u001b[39merror_in_function)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:165\u001b[0m, in \u001b[0;36mAssert\u001b[1;34m(condition, data, summarize, name)\u001b[0m\n\u001b[0;32m    162\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(name, \u001b[39m\"\u001b[39m\u001b[39mAssert\u001b[39m\u001b[39m\"\u001b[39m, [condition, data]) \u001b[39mas\u001b[39;00m name:\n\u001b[1;32m--> 165\u001b[0m   xs \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_n_to_tensor(data)\n\u001b[0;32m    166\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(x\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m {dtypes\u001b[39m.\u001b[39mstring, dtypes\u001b[39m.\u001b[39mint32} \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m xs):\n\u001b[0;32m    167\u001b[0m     \u001b[39m# As a simple heuristic, we assume that string and int32 are\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# on host to avoid the need to use cond. If it is not case,\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39m# we will pay the price copying the tensor to host memory.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     \u001b[39mreturn\u001b[39;00m gen_logging_ops\u001b[39m.\u001b[39m_assert(condition, data, summarize, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAssert\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1790\u001b[0m, in \u001b[0;36mconvert_n_to_tensor\u001b[1;34m(values, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m   1767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_n_to_tensor\u001b[39m(values, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, preferred_dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1768\u001b[0m   \u001b[39m\"\"\"Converts `values` to a list of `Tensor` objects.\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m \n\u001b[0;32m   1770\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1788\u001b[0m \u001b[39m      value.\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1790\u001b[0m   \u001b[39mreturn\u001b[39;00m internal_convert_n_to_tensor(\n\u001b[0;32m   1791\u001b[0m       values\u001b[39m=\u001b[39;49mvalues,\n\u001b[0;32m   1792\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1793\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1794\u001b[0m       preferred_dtype\u001b[39m=\u001b[39;49mpreferred_dtype,\n\u001b[0;32m   1795\u001b[0m       as_ref\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1757\u001b[0m, in \u001b[0;36minternal_convert_n_to_tensor\u001b[1;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[0;32m   1755\u001b[0m   n \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (name, i)\n\u001b[0;32m   1756\u001b[0m   ret\u001b[39m.\u001b[39mappend(\n\u001b[1;32m-> 1757\u001b[0m       convert_to_tensor(\n\u001b[0;32m   1758\u001b[0m           value,\n\u001b[0;32m   1759\u001b[0m           dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1760\u001b[0m           name\u001b[39m=\u001b[39;49mn,\n\u001b[0;32m   1761\u001b[0m           as_ref\u001b[39m=\u001b[39;49mas_ref,\n\u001b[0;32m   1762\u001b[0m           preferred_dtype\u001b[39m=\u001b[39;49mpreferred_dtype,\n\u001b[0;32m   1763\u001b[0m           ctx\u001b[39m=\u001b[39;49mctx))\n\u001b[0;32m   1764\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1691\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1692\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1694\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1695\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1698\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    342\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    287\u001b[0m dtype_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mtensor_value\u001b[39m.\u001b[39mtensor\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    288\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: tensor_value, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value}\n\u001b[1;32m--> 289\u001b[0m const_tensor \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    290\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mConst\u001b[39;49m\u001b[39m\"\u001b[39;49m, [], [dtype_value\u001b[39m.\u001b[39;49mtype], attrs\u001b[39m=\u001b[39;49mattrs, name\u001b[39m=\u001b[39;49mname)\u001b[39m.\u001b[39moutputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    292\u001b[0m \u001b[39mif\u001b[39;00m op_callbacks\u001b[39m.\u001b[39mshould_invoke_op_callbacks():\n\u001b[0;32m    293\u001b[0m   \u001b[39m# TODO(b/147670703): Once the special-op creation code paths\u001b[39;00m\n\u001b[0;32m    294\u001b[0m   \u001b[39m# are unified. Remove this `if` block.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m   callback_outputs \u001b[39m=\u001b[39m op_callbacks\u001b[39m.\u001b[39minvoke_op_callbacks(\n\u001b[0;32m    296\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtuple\u001b[39m(), attrs, (const_tensor,), op_name\u001b[39m=\u001b[39mname, graph\u001b[39m=\u001b[39mg)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:693\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    691\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    692\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 693\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    694\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    695\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3776\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3773\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3774\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3775\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3776\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3777\u001b[0m       node_def,\n\u001b[0;32m   3778\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3779\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3780\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3781\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3782\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3783\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3784\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3785\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3786\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2171\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2169\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2170\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> 2171\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   2172\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2173\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kaczm\\.conda\\envs\\tf2.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2010\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   2006\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   2007\u001b[0m                                          serialized)\n\u001b[0;32m   2009\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2010\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   2011\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2012\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   2013\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Results\n",
    "# reading checkpoint if needen\n",
    "#\n",
    "#################################\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TerminateOnNaN,\n",
    ")\n",
    "\n",
    "# training\n",
    "callbacks = [\n",
    "    # EarlyStopping(patience=10, verbose=1),\n",
    "    # ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.0000001, verbose=1),\n",
    "    tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "    ModelCheckpoint(\n",
    "        \"models\\\\3DUNET_lesion_32_32_64\\\\epoch-{epoch:02d}-valloss-{val_loss:.4f}-{val_precision_1:.2f}-{val_recall:.2f}.hdf5\",\n",
    "        verbose=1,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True,\n",
    "    ),\n",
    "    TerminateOnNaN(),\n",
    "]\n",
    "epochs = 30\n",
    "\n",
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks,\n",
    "    initial_epoch=0,\n",
    ")\n",
    "\n",
    "\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "# save to json:\n",
    "hist_json_file = \"history.json\"\n",
    "with open(hist_json_file, mode=\"w\") as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv:\n",
    "hist_csv_file = \"history.csv\"\n",
    "with open(hist_csv_file, mode=\"w\") as f:\n",
    "    hist_df.to_csv(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ad702f97-a4e1-4759-9d76-acc0a704cf80/assets\n"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "np.save(\"3Dunet_history_lesion.npy\", np.array(history))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a zrób testowy trening od modelu do wątroby :))) mnoże będzie lepiej!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(r\"models\\\\3DUNET_lesion_32_32_64\\\\epoch-23-valloss-0.0288-0.72-0.74.hdf5\")\n",
    "model.load_weights(\n",
    "    r\"models\\\\3DUNET_lesion_32_32_64\\\\epoch-27-valloss-0.0158-0.69-0.77.hdf5\"\n",
    ")\n",
    "\n",
    "\n",
    "# model.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\LITS_Challenge\\Training_Batch_1\\volume-0.nii\n",
      "data\\LITS_Challenge\\Training_Batch_1\\segmentation-0.nii\n"
     ]
    }
   ],
   "source": [
    "# let's start with normal image and make some predictions\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load .nii file\n",
    "\n",
    "# def few funtion to make predictions, WIP, they will be later added to Nii class\n",
    "\n",
    "\n",
    "def preprocessing_3d(t1) -> np.ndarray:\n",
    "    min = -200\n",
    "    max = 200\n",
    "    t1 = np.where(t1 < min, min, t1)\n",
    "    t1 = np.where(t1 > max, max, t1)\n",
    "    t1 -= min\n",
    "    return t1 / max\n",
    "\n",
    "\n",
    "def label_seperator_liver(img):\n",
    "    img = np.where(img == 2, 1, img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def label_seperator_lesion(img):\n",
    "    img = np.where(img == 1, 0, img)\n",
    "    img = np.where(img == 2, 1, img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def reading_data(path: str) -> np.ndarray:\n",
    "    sitk_t1 = sitk.ReadImage(path)\n",
    "    t1 = sitk.GetArrayFromImage(sitk_t1)\n",
    "    t1 = t1.reshape(t1.shape[0], t1.shape[1], t1.shape[2], 1)\n",
    "\n",
    "    t1 = tf.dtypes.cast(t1, tf.float32)\n",
    "\n",
    "    return t1\n",
    "\n",
    "\n",
    "def label_seperator_liver(img):\n",
    "    img = np.where(img == 2, 1, img)\n",
    "    return img\n",
    "\n",
    "\n",
    "path = \"data\\\\LITS_Challenge\\\\Training_Batch_1\"\n",
    "files_volume = glob.glob(path + \"\\\\volume*.nii\")\n",
    "files_segmenation = glob.glob(path + \"\\\\segmentation*.nii\")\n",
    "\n",
    "print(files_volume[0])\n",
    "print(files_segmenation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.0\n",
      "(517, 512, 512, 1)\n",
      "(517, 512, 512, 1)\n",
      "(517, 512, 512, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_id = 12\n",
    "volume_1 = reading_data(files_volume[file_id])\n",
    "volume_1 = preprocessing_3d(volume_1)\n",
    "print(np.min(volume_1))\n",
    "print(np.max(volume_1))\n",
    "\n",
    "\n",
    "seg_1 = reading_data(files_segmenation[file_id])\n",
    "liver_1 = label_seperator_liver(seg_1)\n",
    "seg_1 = label_seperator_lesion(seg_1)\n",
    "seg_1 = tf.keras.utils.to_categorical(seg_1, 2)\n",
    "print(volume_1.shape)\n",
    "print(liver_1.shape)\n",
    "print(seg_1.shape)\n",
    "\n",
    "\n",
    "volume_1 = np.where(liver_1 > 0, volume_1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) going from top to the bottom, all slices even without the liver\n",
    "# data preparation -> spreading data to quboids\n",
    "\n",
    "def get_prediction(volume_1,seg_1):\n",
    "    n = (volume_1.shape[0] // 32) * 2 - 1\n",
    "    m = (volume_1.shape[1] // 64) * 2 - 1\n",
    "\n",
    "    chunk_size = 32\n",
    "    cords_shift = chunk_size // 2\n",
    "\n",
    "    #print(chunk_size)\n",
    "    #print(cords_shift)\n",
    "\n",
    "    total_q = n * m * m  # total quboids\n",
    "\n",
    "    all_quboids = np.zeros(\n",
    "        (int(total_q // 4 + 1), 4, chunk_size, chunk_size * 2, chunk_size * 2, 1)\n",
    "    )\n",
    "    all_quboids_seg = np.zeros(\n",
    "        (int(total_q // 4 + 1), 4, chunk_size, chunk_size * 2, chunk_size * 2, 2)\n",
    "    )\n",
    "    preds = np.zeros(\n",
    "        (int(total_q // 4 + 1), 4, chunk_size, chunk_size * 2, chunk_size * 2, 2)\n",
    "    )\n",
    "    #print(all_quboids.shape)\n",
    "    batch_no = 0\n",
    "    q = 0\n",
    "    for z in range(n):  # z direction\n",
    "        for y in range((m)):\n",
    "            for x in range((m)):\n",
    "                tmp_image = volume_1[\n",
    "                    z * cords_shift : z * cords_shift + chunk_size,\n",
    "                    y * cords_shift * 2 : y * cords_shift * 2 + chunk_size * 2,\n",
    "                    x * cords_shift * 2 : x * cords_shift * 2 + chunk_size * 2,\n",
    "                    0:1,\n",
    "                ]\n",
    "\n",
    "                tmp_seg = seg_1[\n",
    "                    z * cords_shift : z * cords_shift + chunk_size,\n",
    "                    y * cords_shift * 2 : y * cords_shift * 2 + chunk_size * 2,\n",
    "                    x * cords_shift * 2 : x * cords_shift * 2 + chunk_size * 2,\n",
    "                    0:2,\n",
    "                ]\n",
    "\n",
    "                all_quboids[batch_no, q, :, :, :, 0:1] = tmp_image\n",
    "                all_quboids_seg[batch_no, q, :, :, :, 0:2] = tmp_seg\n",
    "                q += 1\n",
    "                if q > 3:\n",
    "                    batch_no += 1\n",
    "                    q = 0\n",
    "\n",
    "                \"\"\"\n",
    "                tmp_seg = seg_1[\n",
    "                    z * cords_shift : z * cords_shift + chunk_size,\n",
    "                    y * cords_shift * 2 : y * cords_shift * 2 + chunk_size * 2,\n",
    "                    x * cords_shift * 2 : x * cords_shift * 2 + chunk_size * 2,\n",
    "                    0:2,\n",
    "                ]\"\"\"\n",
    "\n",
    "\n",
    "    # prediction for whole\n",
    "\n",
    "\n",
    "    for i in range(len(all_quboids)):\n",
    "        if np.any(all_quboids[i] > 0):\n",
    "            preds[i] = model.predict(all_quboids[i])\n",
    "\n",
    "    #print(preds.shape)\n",
    "    #print(\"done\")\n",
    "\n",
    "    a = 0\n",
    "    final_preds = np.zeros((np.shape(seg_1)))\n",
    "    #print(final_preds.shape)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for z in range(n):  # z direction\n",
    "        for y in range((m)):\n",
    "            for x in range((m)):\n",
    "                final_preds[\n",
    "                    z * cords_shift: z * cords_shift + chunk_size,\n",
    "                    y * cords_shift * 2: y * cords_shift * 2 + chunk_size * 2,\n",
    "                    x * cords_shift * 2: x * cords_shift * 2 + chunk_size * 2,\n",
    "                    0:2,\n",
    "                ] += preds[i, j, :, :, :, 0:2]\n",
    "                j += 1\n",
    "                if j > 3:\n",
    "                    i += 1\n",
    "                    j = 0\n",
    "\n",
    "                a += 1\n",
    "\n",
    "\n",
    "    final_preds = final_preds / 8\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuild the standart view by averanging\n",
    "\n",
    "def rebuild_volue(preds,seg_1):\n",
    "    n = (seg_1.shape[0] // 32) * 2 - 1\n",
    "    m = (seg_1.shape[1] // 64) * 2 - 1\n",
    "    a = 0\n",
    "    \n",
    "\n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (75,512,512,1) (501,512,512,2) () ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m lesion \u001b[39m=\u001b[39m final_preds[:, :, :, \u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m lesion \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mwhere(liver_1 \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m, final_preds, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m lesion \u001b[39m=\u001b[39m lesion[:, :, :, \u001b[39m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmax(lesion))\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (75,512,512,1) (501,512,512,2) () "
     ]
    }
   ],
   "source": [
    "lesion = final_preds[:, :, :, 0:1]\n",
    "lesion = np.where(liver_1 > 0, final_preds, 0)\n",
    "lesion = lesion[:, :, :, 1]\n",
    "print(np.max(lesion))\n",
    "threshold = 0.01\n",
    "# lesion = np.where(lesion>threshold,1,0)\n",
    "print(np.max(final_preds[:, :, :, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(liver,gt,preds,thresholds=0.5):\n",
    "    TP = tf.keras.metrics.TruePositives(thresholds=threshold)\n",
    "    FP = tf.keras.metrics.FalsePositives(thresholds=threshold)\n",
    "    FN = tf.keras.metrics.FalseNegatives(thresholds=threshold)\n",
    "    \n",
    "    preds = preds[:,:,:,1]\n",
    "    preds = np.where(liver[:,:,:,0]>0,preds,0)\n",
    "\n",
    "    TP.update_state(gt[:, :, :, 1], preds)\n",
    "    FP.update_state(gt[:, :, :, 1], preds)\n",
    "    FN.update_state(gt[:, :, :, 1], preds)\n",
    "\n",
    "    prec = TP.result() / (TP.result() + FP.result())\n",
    "    recall = TP.result() / (TP.result() + FN.result())\n",
    "    return prec, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (75,512,512) (517,512,512) () ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m0.27\u001b[39m\n\u001b[1;32m----> 2\u001b[0m prec, recall \u001b[39m=\u001b[39m get_metrics(volume_1,seg_1,final_preds,threshold)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(prec)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(recall)\n",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m, in \u001b[0;36mget_metrics\u001b[1;34m(liver, gt, preds, thresholds)\u001b[0m\n\u001b[0;32m      4\u001b[0m FN \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFalseNegatives(thresholds\u001b[39m=\u001b[39mthreshold)\n\u001b[0;32m      6\u001b[0m preds \u001b[39m=\u001b[39m preds[:,:,:,\u001b[39m1\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mwhere(liver[:,:,:,\u001b[39m0\u001b[39;49m]\u001b[39m>\u001b[39;49m\u001b[39m0\u001b[39;49m,preds,\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m TP\u001b[39m.\u001b[39mupdate_state(gt[:, :, :, \u001b[39m1\u001b[39m], preds)\n\u001b[0;32m     10\u001b[0m FP\u001b[39m.\u001b[39mupdate_state(gt[:, :, :, \u001b[39m1\u001b[39m], preds)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (75,512,512) (517,512,512) () "
     ]
    }
   ],
   "source": [
    "threshold = 0.27\n",
    "prec, recall = get_metrics(volume_1,seg_1,final_preds,threshold)\n",
    "print(prec)\n",
    "print(recall)\n",
    "\n",
    "plot = False\n",
    "\n",
    "\n",
    "if plot:\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, 15)\n",
    "\n",
    "    for i in range(np.shape(volume_1)[0]):\n",
    "        if np.any(volume_1[i, :, :, 0]) > 0 and np.any(seg_1[i, :, :, 1]) > 0.1:\n",
    "\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(volume_1[i, :, :, 0])\n",
    "            plt.title(\"original volume\")\n",
    "            plt.grid()\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(\"combined predictions\")\n",
    "            plt.imshow(lesion[i, :, :], vmin=0.07, vmax=0.2)\n",
    "            plt.grid()\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"ground truth\")\n",
    "            plt.imshow(seg_1[i, :, :, 1])\n",
    "            plt.grid()\n",
    "            plt.suptitle(f\"{volume_1.shape[0]}_{i}, precition:{np.round(prec,2)} recall {np.round(recall,2)}\")\n",
    "            plt.savefig(f\"results_images/{volume_1.shape[0]}_{i}.png\")\n",
    "            plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 27\n"
     ]
    }
   ],
   "source": [
    "# Metrics loop\n",
    "\n",
    "file_id = 27\n",
    "\n",
    "\n",
    "threshold = 0.27\n",
    "\n",
    "volume_1 = reading_data(files_volume[file_id])\n",
    "volume_1 = preprocessing_3d(volume_1)\n",
    "\n",
    "\n",
    "seg_1 = reading_data(files_segmenation[file_id])\n",
    "liver_1 = label_seperator_liver(seg_1)\n",
    "seg_1 = label_seperator_lesion(seg_1)\n",
    "seg_1 = tf.keras.utils.to_categorical(seg_1, 2)\n",
    "volume_1 = np.where(liver_1 > 0, volume_1, 0)\n",
    "final_preds = get_prediction(volume_1,seg_1)\n",
    "\n",
    "\n",
    "prec, recall = get_metrics(volume_1,seg_1,final_preds,threshold)\n",
    "with open(\"results.txt\",'a+') as f:\n",
    "    f.write(f\"file_id: {file_id}, z: {volume_1.shape[0]}, prec: {np.round(prec,2)}, recall: {np.round(recall,2)}\\n\")\n",
    "\n",
    "\n",
    "del volume_1\n",
    "del seg_1\n",
    "del final_preds\n",
    "print(f\"done {file_id}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file_id: 0, z: 75, prec: 0.07000000029802322, recall: 0.0\n",
    "\n",
    "file_id: 1, z: 123, prec: 0.5199999809265137, recall: 0.23000000417232513\n",
    "\n",
    "file_id: 2, z: 501, prec: 0.5799999833106995, recall: 0.949999988079071\n",
    "\n",
    "file_id: 3, z: 466, prec: 0.6399999856948853, recall: 0.8199999928474426\n",
    "\n",
    "file_id: 4, z: 455, prec: 0.11999999731779099, recall: 0.3700000047683716\n",
    "\n",
    "file_id: 5, z: 605, prec: 0.07000000029802322, recall: 0.6600000262260437\n",
    "\n",
    "file_id: 6, z: 588, prec: 0.3100000023841858, recall: 0.8100000023841858\n",
    "\n",
    "file_id: 7, z: 565, prec: 0.0, recall: 0.0\n",
    "\n",
    "file_id: 8, z: 689, prec: 0.8600000143051147, recall: 0.8500000238418579\n",
    "\n",
    "file_id: 9, z: 826, prec: 0.699999988079071, recall: 0.9800000190734863\n",
    "\n",
    "file_id: 10, z: 845, prec: 0.7599999904632568, recall: 0.6800000071525574\n",
    "\n",
    "file_id: 11, z: 547, prec: 0.30000001192092896, recall: 0.7200000286102295\n",
    "\n",
    "file_id: 12, z: 517, prec: 0.7699999809265137, recall: 0.7900000214576721\n",
    "\n",
    "file_id: 13, z: 574, prec: 0.019999999552965164, recall: 0.4300000071525574\n",
    "\n",
    "file_id: 14, z: 437, prec: 0.7699999809265137, recall: 0.2199999988079071\n",
    "\n",
    "file_id: 15, z: 247, prec: 0.47999998927116394, recall: 0.9900000095367432\n",
    "\n",
    "file_id: 16, z: 391, prec: 0.5, recall: 1.0\n",
    "\n",
    "file_id: 17, z: 276, prec: 0.0, recall: 0.0\n",
    "\n",
    "file_id: 18, z: 601, prec: 0.1599999964237213, recall: 0.8600000143051147\n",
    "\n",
    "file_id: 19, z: 668, prec: 0.6899999976158142, recall: 0.9900000095367432\n",
    "\n",
    "file_id: 20, z: 861, prec: 0.6200000047683716, recall: 0.9399999976158142\n",
    "\n",
    "file_id: 21, z: 534, prec: 0.33000001311302185, recall: 0.8100000023841858\n",
    "\n",
    "file_id: 22, z: 841, prec: 0.75, recall: 0.9900000095367432\n",
    "\n",
    "file_id: 23, z: 537, prec: 0.0, recall: 0.0\n",
    "\n",
    "file_id: 24, z: 518, prec: 0.550000011920929, recall: 0.9900000095367432\n",
    "\n",
    "file_id: 25, z: 541, prec: 0.6100000143051147, recall: 0.9900000095367432\n",
    "\n",
    "file_id: 26, z: 541, prec: 0.5799999833106995, recall: 0.9700000286102295\n",
    "\n",
    "file_id: 27, z: 549, prec: 0.5400000214576721, recall: 0.9900000095367432\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) only part with the liver\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TODO\n",
    "\n",
    "# 1) zdefiniować liczenie metryk (tj metryki i z czego mają się liczyć)\n",
    "# 2) przeliczyć dla każdego skanu\n",
    "# 3) przeskalować małe skany na duże i przeliczyć znowu\n",
    "# 4) pomyśleć jak można sprawdzać dice od wielkości"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wnioski:\n",
    "\n",
    "\n",
    "- działa, cały pipeline działa\n",
    "- sieć wymaga modyfikacji do tego podejścia\n",
    "\n",
    "- wykrywa poprawie większe zmiany, nie wykrywa małych, jest to związane z architekturą sieci\n",
    "-- do tego problemu trzeba to zrobić inaczej, więcej kanałów na normalnym poziomie, mniej na niższym, ew zrobić nawet jednopoziomowy encoder dekoder (i więcej cech)\n",
    "- podejście nie wydaje się złe, tylko wymaga faktycznie dostosowania pod siebie kilku aspektów, szczególnie do szuaknia małych zmian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9b479fa97f672ded16c3aa2c05a2af574f512ec55675434aaf269f9ffd0698c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
